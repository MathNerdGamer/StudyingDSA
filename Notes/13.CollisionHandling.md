# Collision Handling

* There are two main categories of collision handling:
1. **Closed Addressing** - In closed addressing, all collisions are stored at the same place by some means.
2. **Open Addressing** - In open addressing, collisions result in data being stored in different locations based on the initial location where the collision occured.

## External Chaining

* *External chaining* is a closed addressing policy where each position in the backing array is a reference to a linked list where values whose keys collide are stored.

* In the example where we take phone numbers as keys and compress them into indices for the backing array by taking them modulo the capacity of the array, any phone numbers which ended up going to the same index would simply be appended to the linked list whose reference resides at the index.

* When using linked lists, we don't run out of space. However, if too many items end up stored at the same index, this will impact runtimes.
    * This means the worst case runtimes for `put()`/`get()`/`remove()` operations are $O\left(n\right)$, since everything *could* go to the same index.
    * As a result, we should consider a probabilistic approach to hash maps, including an average case analysis.
    * In the courses linked to in the [previous note](./12.HashMaps.md), more theory is developed which shows when hash maps will have $O\left(1\right)$ *expected* (*amortized*) `put()`/`get()`/`remove()` (amortized for `put()`, since we have to take rebuilding the backing array into account).

* The load factor of a hash map is still `size / capacity`, where the `size` counts each element in each linked list.
    * As a result, even if everything hashes to just one or two indices, if the load factor gets large enough to trigger a resize, the resize will still occur.
    * When resizing, often one takes a new capacity that is two times the old capacity, plus one.
    * When this happens, everything must be rehashed and recompressed.

## Linear Probing

* *Probing* in a hash map is an open addressing strategy where:
    * The backing array may only hold a single entry at each index.
    * Entries may not be located precisely at the originally calculated index, which usually happens when a collision has occured.
    * When a searching for or inserting a key-value pair, some strategy is used to "probe" the array around the original index to find the appropriate secondary address.

* *Linear probing* is a probing strategy where the index is incremented by 1 when a collision occurs.
    * $\mathrm{index} = \left(\mathrm{originalIndex} + h\right)\mod \mathrm{array.length}$ - here, `h` is the number of times we've probed so far (starting from 0).
    * We stop our probe if:
        * We've found our entry (in the case of search).
        * We've found a `null` spot (either a search failure or a place to insert a new entry).
        * We've probed every possible index (which can be done via a loop, `for(int h = 0; h < array.length; h++)`).

* When implementing `put()`, we do as above.

* When implementing `remove()`, we do as above, but we have to be careful.
    * If we find our entry to remove, we can't use `null`, because we would prematurely stop a search if another entry has the same hash after the item we're removing.
    * Instead, we have to place some kind of marker to indicate that the entry was deleted.
        * One way to do this is to have a wrapper object for entries which include both the key-value pair and a `boolean` entry that can be flipped between `true`/`false` to toggle whether the entry was deleted or not.
        * Another way that can be more memory efficient would be to make use of any additional structure on the data being stored.
            * For a basic example of this, if a hash map is holding integers that are always positive, then the sign bit can be used to mark deleted entries.
        * Such markers are called *tombstones*.

* As a result, when using `put()`, there are four cases:
    * Valid (not `null` and not deleted) entry, not equal - Probe forward.
    * Valid entry, equal - Finish, nothing to be done.
    * Deleted entry - Save this index, return later to insert if no duplicates found.
    * `null` entry - Insert here immediately if no deleted entry index saved, since duplicates of the entry we're inserting are impossible beyond this point.

* Similarly to external chaining, when resizing the array, we must:
    * Create a new backing array by doubling and adding 1 to the old capacity.
    * Loop through the old array and rehash things to the new array.
    * We skip over all tombstone markers.

* Note that tombstones *can* hurt the performance of a hash map.
    * When using `put()`/`remove()`, assuming the key is not in the table, we could end up looping over the entire array, because we may have a bunch of tombstones in our way.
    * There are some ways to combat this:
        * One way is to somehow take tombstones into account as part of the load factor.
        * We could intentionally resize our array if we know that we'll be removing many entries (since it'll take a long time anyway, we could use this opportunity to clean things up).
        * We could use a sufficiently "good" hash function the avoids collisions to enough of a degree that it'll be unlikely for tombstones to pile up.
            * This final topic comes up in some of the material in the courses recommend in the [previous note](./12.HashMaps.md).

## Quadratic Probing

* An issue that linear probing can easily cause is having too many entries in a large, contiguous block, which would necessitate a lot of probing and, hence, runtime.
    * This problem is known as *primary clustering*.

* One way to mitigate this is by using a different probing technique, such as *quadratic probing*.

* Like linear probing, everything is stored directly into the backing array. However, traversal when probing is slightly different.
    * Instead of moving forward by 1 at each step, we set our index at step $h$ to be $\mathrm{index} = \left(\mathrm{originalIndex} + h^{2}\right)\mod \mathrm{array.length}$, hence the name "quadratic probing" instead of linear.
    * This helps to break up the space between entries when collisions occur, meaning that we'll be less likely to have a large graveyard of tombstones all in one place.

* An issue with quadratic probing that linear probing does not have is that we may accidentally enter a probing pattern that only touches a few cells.
    * For example, suppose we wish to insert into a hash table with a backing array of length 7 and that we initially probe index 1. Suppose, further, that cells 1, 2, 3, and 5 have entries, while cells 0, 4, and 6 are empty. What happens?
        * We probe at index 1, find it full, and move forward: $\left(1 + 1^{2}\right)\mod 7 = 2$
        * We probe at index 2, find it full, and move forward: $\left(1 + 2^{2}\right)\mod 7 = 5$
        * At index 5: $\left(1 + 3^{2}\right)\mod 7 = 3$
        * At index 3: $\left(1 + 4^{2}\right)\mod 7 = 3$
        * At index 3 (again): $\left(1 + 5^{2}\right)\mod 7 = 5$
        * At index 5 (again): $\left(1 + 6^{2}\right)\mod 7 = 2$
        * This pattern will repeat, because we're working modulo 7.
    * This is known as *secondary clustering*.

* Handling this "infinite probing" problem requires some care.
    * We could resize our table over and over again until we hit a spot, where we detect our infinite probe situation by limiting the number of probes to the number of cells in our table.
    * Alternatively, prime numbers could be used as our table sizes, along with a maximum load factor of 0.5.
    * Both of the above solutions can be rather costly, and the first, in particular, can still have pathological examples where multiple resizes are necessary (and, in fact, can be made to resize an arbitrary number of times).

To prove that the second strategy works, we need only prove the following.

**Theorem.** Let $p$ be a prime number and let $t$ be any integer. Then, the first $\displaystyle{\left\lfloor\frac{p}{2}\right\rfloor}$ elements of the sequence $\left(a_{k}\right)_{k\geq 0}$ defined by $a_{k} = \left(t + k^{2}\right)\mod p$ are distinct.

**Proof.**

Suppose that there exist indices $\displaystyle{0\leq i < j\leq \left\lfloor\frac{p}{2}\right\rfloor}$ such that $t + i^{2} \equiv t + j^{2}\pmod{p}$. Then, $i^{2}\equiv j^{2}\pmod{p}$, which means

$$\left(i-j\right)\left(i+j\right)\equiv 0\pmod{p}.$$

Note that $i-j\not\equiv 0\pmod{p}$ since $i\not\equiv j\pmod{p}$, because, otherwise, that would mean that $i = j$, as they're between $0$ and $p$.

On the other hand, if $i + j\equiv 0\pmod{p}$, then $i+j = p$. However, since $\displaystyle{i < j \leq \left\lfloor\frac{p}{2}\right\rfloor}$, this means that $\displaystyle{i + j < 2j \leq 2\cdot \left\lfloor\frac{p}{2}\right\rfloor \leq p}$, a contradiction.

Therefore, it must be the case that there are no such indices $i$ and $j$.

**QED**

**N.B.:** You may notice that the table size in our example exhibiting secondary clustering *was* prime. However, the load factor was $4/7 > 0.5$, and so it failed the second part of the second strategy. However, if were maintaining a load factor less than 0.5, then the fourth item would have triggered a resize to either 13 or 17 (primes which are roughly twice as large).

## Double Hashing