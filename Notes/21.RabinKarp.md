# Pattern Matching Algorithms III: Rabin-Karp

* The previous two algorithms were modifications of the brute force approach that changed how we shifted the pattern.
    * The brute force approach na√Øvely starts from the beginning and just tries finding a match at every character.
    * Boyer-Moore (BM) uses a last occurrence table to realign the pattern when a mismatch occurs, which has the potential to skip over large portions of the text.
    * Knuth-Morris-Pratt (KMP) uses a failure table to realign the pattern in such a way that every character before the character that had the mismatch is aligned correctly.

* Rabin-Karp (RK), on the other hand, changes when we do a comparison at all, rather than changing how we shift the pattern after a comparison.
    * This is done with via hashing, using what's called the *Rabin Fingerprint Rolling Hash*.

* Like BM and KMP, RK starts by preprocessing.
    * However, unlike BM and KMP, *both* text and pattern are preprocessed.

## Rabin Fingerprint Rolling Hash

* When RK gets a pattern and text, a hash is made for the pattern and substrings of the text.
    * Only the length-$m$ substrings are hashed, where $m$ is the length of the pattern.

* Only when there are collisions does an actual comparison occur.
    * This is because two different hashes *must* be to two different strings, but two different strings *can* have the same hash.

* If our hash function is sufficiently resistant to collisions while also being quick to compute, then Rabin-Karp can have considerable performance gains over Boyer-Moore and Knuth-Morris-Pratt.

* The issue we have it that a generic hash function doesn't necessarily fit our needs.
    * To hash each $m$-length substring, we would perform $n - m + 1$ hashes.
    * If we hash each substring independently of each other, we would need $\Omega\left(m\right)$ time to hash each one, as we would need to (at minimum) read each character of the pattern to have an effective hash function.
    * This would require $\Omega\left(m\left(n-m\right)\right) = \Omega\left(mn\right)$ steps to complete, not even counting the comparisons necessary to find matches.
    * This would not be an improvement over a brute force.

* Thankfully, there is a type of hash function that can be used here, called a *rolling hash*.
    * A rolling hash is one which takes $O\left(1\right)$ amortized time per hash by first performing a hash on an initial substring, and then taking $O\left(1\right)$ time to update when given the next substring.

* One rolling hash is described as follows:
    * Pick a (large) prime $p$.
    * Pick a hash function $h$ which maps single characters to positive integers.
    * Define a hash function of strings $s$ by $\displaystyle{H\left(s\right) = \sum_{0\leq k\leq m-1} h\left(s\left[k\right]\right) p^{m-1-k},}$ where $s\left[k\right]$ is the $k\rm{th}$ character of the string $s$.
        * Essentially, we are considering a base-$p$ number whose "digits" are the hash values of each character of our string.
    * When we update our string $s$ to $s'$ by moving our "window" into the text over by one, we're essentially removing the first character of $s$ and appending a new character at the end.
        * Therefore, $H\left(s'\right) = \left(H\left(s\right) - h\left(s\left[0\right]\right)\cdot p^{m-1}\right) \cdot p + h\left(c'\right)$, where $c' = s'\left[m-1\right]$ is the new character appended to the end to form $s'$.
        * Since we will have already computed $H\left(s\right)$ before, this is just a constant number of operations that take constant time (since we'll be working with fixed-width integers), hence an $O\left(1\right)$ operation.
        * Therefore, amortizing the cost over every substring, we'll only incur a penalty of $O\left(m\right)$ from the initial substring, and then $O\left(1\right)$ operations after, we have an amortized cost of $\displaystyle{\frac{O\left(m\right) + O\left(n-m\right)}{n - m + 1} = O\left(1\right)}$ for our rolling hash, assuming $n \geq m$ (which is the only case where we can even find matches).

## The Algorithm

* Since we'll be working with fixed-width integers (such as unsigned 64-bit integers), there's always a chance we overflow, and so there may be many opportunities for collisions.
    * Having a bunch of collisions would make our algorithm basically a slower brute force, because we could be doing a bunch of preprocessing that end up making us check every character anyway.
    * However, this is highly unlikely.
    * In fact, although we won't prove it, it is the case that Rabin-Karp has an average-case $O\left(m + n\right)$ runtime.

* Given this rolling hash, we can easily implement RK.
    * Let's assume we've implemented a nice hash function based on our description above, and call it `RabinHash(String)`.
    ```java
    public static int RabinKarpSingle(String text, String pattern) {
        int n = text.length();
        int m = pattern.length();
        int patternHash = RabinHash(pattern);

        for (int tIdx = 0; tIdx <= n - m; tIdx++) {

            if (RabinHash(text.substring(tIdx, tIdx + m + 1)) == patternHash) {

                int pIdx = 0;
                for (pIdx = 0; pIdx < m && text[tIdx + pIdx] == pattern[pIdx]; pIdx++) {} // Intentionally blank
                
                if (pIdx == m) {
                    return tIdx;
                }
            }
        }
    }
    ```

**Theorem.** The RK Algorithm has the following complexities:

1. If there are no occurrences of the pattern in the text:
    * Best-case: $O\left(m + n\right)$
    * Worst-case: $O\left(mn\right)$
2. If we're looking only for a single occurrence:
    * Best-case: $O\left(m\right)$
    * Worst-case: $O\left(mn\right)$
3. If we're looking for all occurrences:
    * Best-case: $O\left(m + n\right)$
    * Worst-case: $O\left(mn\right)$

**Proof.**

As stated above, if our hash ends up colliding a lot, we get essentially a worse brute force, which is $O\left(mn\right)$.

For the best-case runtimes, in all cases, we have no collisons besides (in cases 2 and 3) a single occurrence.

In cases 1 and 3, since we have to go through the entire text (in order to confirm no occurrences or to collect them all), and since our hash is $O\left(1\right)$, this gives an $O\left(n\right)$ cost added to our $O\left(m\right)$ cost for the pattern hash, which totals to $O\left(m + n\right)$.

In case 2, since we terminate after finding a match, our best case is that the match occurs immediately, and so we have another $O\left(m\right)$ cost to both hash the first substring and then confirm that it equals the pattern, for an overall $O\left(m\right)$ runtime.

**QED**

**Next: [Graphs](./22.Graphs.md)**