# BST Operations

* In the following, assume we have a `Node<T>` class with a constructor which takes in the data to be stored and, optionally, the `parent` and `left`/`right` pointers.

* We also assume we have a method `isEmpty()` that returns `true`/`false` depending on if the tree is empty or not.

## BST Search
* Binary Search Trees (BSTs) are meant to act sort-of like the binary search algorithm, which halves the search space in each step.

* In a BST, search is implemented by, starting from `root`, comparing with the current node, and proceeding to the `left` child, if the data being searched for is less than the current node's data, or the `right` child.

* This can be done recursively or iteratively.
    * Recursive:
        ```java
        public bool contains(T data) {
            return searchRecursive(root, data);
        }

        private bool searchRecursive(Node<T> currentNode, T data) {
            if (currentNode == null) {
                return false;
            }

            int comparison = data.compareTo(currentNode.data);

            if (comparison < 0) {
                searchRecursive(currentNode.left, data);
            } else if (comparison > 0) {
                searchRecursive(currentNode.right, data);
            } else {
                return true;
            }
        }
        ```
    * Iterative:
        ```java
        public boolean contains(T data) {
            Node<T> currentNode = root;

            while (currentNode != null) {
                int comparison = data.compareTo(currentNode.data);

                if (comparison < 0) {
                    currentNode = currentNode.left;
                } else if (comparison > 0) {
                    currentNode = currentNode.right;
                } else {
                    return true;
                }
            }

            return false;
        }
        ```

## BST Insertion

* Insertion is similar to search, except we add a new node in if the "search" fails.
    * If a node is already in the tree with the data, we will do nothing.

* A slight difference between insertion and searching is that insertion involves "look ahead," where we never actually reach a `null` node, where what would be a step into a `null` node is actually the condition which terminates out iteration/recursion.

* Another method, which would be more useful for more complicated trees, is a concept known as "Pointer Reinforcement," where we use return values to set child pointers. Each recursion is actually an assignment to a child pointer, and the final level of recursion is what actually sets the new child node.

* As before, this can be done recursively or iteratively.
    * Recursive (Look Ahead):
        ```java
        public void insert(T data) {
            if (isEmpty()) {
                root = new Node<T>(data);
            } else {
                insertRecursive(root, data);
            }

            size++;
        }

        private void insertRecursive(Node<T> currentNode, T data) {
            int comparison = data.compareTo(currentNode.data);

            if (comparison < 0) {
                if (currentNode.left == null) {
                    currentNode.left = new Node<T>(data, currentNode);
                    return;
                }

                insertRecursive(currentNode.left, data);
            } else if (comparison > 0) {
                if (currentNode.right == null) {
                    currentNode.right = new Node<T>(data, currentNode);
                    return;
                }

                insertRecursive(currentNode.right, data);
            }
        }
        ```
    * Recursive (Pointer Reinforcement):
        ```java
        public void insert(T data) {
            if (isEmpty()) {
                root = new Node<T>(data);
            } else {
                root = insertRecursive(root, data);
            }
            
            size++;
        }

        private Node<T> insertRecursive(Node<T> currentNode, T data) {
            if (currentNode == null) {
                size++;
                return new Node<T>(data);
            }

            int comparison = data.compareTo(currentNode.data);

            if (comparison < 0) {
                currentNode.left = insertRecursive(currentNode.left, data);
                currentNode.left.parent = currentNode;
            } else if (comparison > 0) {
                currentNode.right = insertRecursive(currentNode.right, data);
                currentNode.right.parent = currentNode;
            }
            
            return currentNode;
        }
        ```
    * Iterative:
        ```java
        public void insert(T data) {
            if (isEmpty()) {
                root = new Node<T>(data);
                return;
            }

            Node<T> previousNode = null;
            Node<T> currentNode = root;

            int comparison;

            while (currentNode != null) {
                previousNode = currentNode;

                comparison = data.compareTo(currentNode.data);

                if (comparison < 0) {
                    currentNode = currentNode.left;
                } else if (comparison > 0) {
                    currentNode = currentNode.right;
                } else {
                    return;
                }
            }

            Node<T> newNode = new Node<>(data, previousNode);
            
            if (comparison < 0) {
                previousNode.left = newNode;
            } else {
                previousNode.right = newNode;
            }

            size++;
        }
        ```

## BST Removal

* This is the most complex of the three operations to implement.

* When there's a call to `remove(T)`, there are four cases to handle:
    * The element is not in the tree.
        * In this case, just return `null` or throw an exception.
    * The element is in the tree and is stored in a leaf node.
        * In this case, just unlink the node from the tree by erasing the `parent` node's pointer to it.
    * The element is in the three and is stored in a node with one child.
        * In this case, if relink the child to the parent of the node to be removed.
    * The element is in the tree and has two child pointers. This is the most difficult case.
        * Before removing, we find either the predecessor or successor the node we wish to remove.
        * Once this other node is found, we swap the data they store.
        * Then, we remove the node that used to hold the predecessor/successor value.

* In the fourth case, the predecessor or successor node will be in one of the other two cases.

**Proposition.** A node with two children always have a predecessor and successor, and these nodes always have fewer than two children.

**Proof.**

A node having two children means that there are smaller nodes and larger nodes, and so the largest of the smaller nodes is the predecessor, and the smallest of the larger nodes is the successor.

For the predecessor of our node, we simply move to the `left` child, and then traverse as far to the right of this subtree as possible. This largest element of the left subtree of our node is the predecessor, and hence it must have no right child.

The successor is the same, except it is the left-most node in the right subtree and, hence, must have no left child.

**QED**

* Here's the iterative code for removing a node using the predecessor. The recursive and successor versions are left as an exercise for the reader.
    ```java
    public void remove(T data) {
        Node<T> currentNode = root;

        while (currentNode != null) {
            int comparison = data.compareTo(currentNode.data);

            if (comparison < 0) {
                currentNode = currentNode.left;
            } else if (comparison > 0) {
                currentNode = currentNode.right;
            } else {
                break;
            }
        }

        if (currentNode == null) {
            return;
        }

        size--;

        if (currentNode.left == null && currentNode.right == null) {
            removeLeaf(currentNode);
        } else if (currentNode.left == null || currentNode.right == null) {
            removeOneChild(currentNode);
        } else {
            removeTwoChild(currentNode);
        }
    }

    private void removeLeaf(Node<T> node) {
        if (node.parent == null) {
            root = null;
        } else if (node == node.parent.left) {
            node.parent.left = null;
        } else {
            node.parent.right = null;
        }
    }

    private void removeOneChild(Node<T> node) {
        if (node == root) {
            if (root.left != null) {
                root = root.left;
            } else {
                root = root.right;
            }
        } else {
            if (node == node.parent.left) {
                if (node.left != null) {
                    node.parent.left = node.left;
                } else {
                    node.parent.left = node.right;
                }
            } else {
                if (node.left != null) {
                    node.parent.right = node.left;
                } else {
                    node.parent.right = node.right;
                }
            }
        }
    }

    private void removeTwoChild(Node<T> node) {
        Node<T> predecessor = node.left;

        while (predecessor.right != null) {
            predecessor = predecessor.right;
        }

        node.data = predecessor.data;

        if (predecessor.left != null || predecessor.right != null) {
            removeOneChild(predecessor);
        } else {
            removeLeaf(predecessor);
        }
    }
    ```

## Analysis of BST Operations

* We will approach our analyses in two steps:
    * First, we'll show their runtimes depend on the height of the BST.
    * Then, we'll look at both the worst-case and average-case for the height (and, hence, of the operations).
        * The average-case analysis is over a uniform distribution of nodes that will be inserted in building the tree, specifically the first node (which will become the root).

### Height-dependence of BST Operations

Recall that the *height* of a tree is the longest `root`-to-leaf path. This should make the following theorem pretty obvious:

**Theorem.** Consider a BST of height $h$. Then, the runtimes of searching, inserting, and removing an element from the BST are $O\left(h\right)$.

**Proof.**

When doing one of these operations, the largest number of steps required would involve the longest `root`-to-leaf path, which requires $O\left(h\right)$ steps to follow.

For search and insertion, we do this once, and then perform a constant number of extra steps, such as returning `true`/`false` for search, or either doing nothing (if the data is already stored) or linking a new node when inserting. Therefore, the complexities of those two are $O\left(h\right)$.

For removal, in the first three cases above (element is not found, in a leaf, or in a node with one child), there is a constant number of additional steps (returning `null`/throwing exception, unlinking a leaf, or relinking a node's `parent` and child to each other), so these two cases take $O\left(h\right)$ steps.

In the two-child case, we need to find the predecessor or successor of the node to be removed, swap their data, and then remove the predecessor/successor node. Recall that the removal of a predecessor/successor node is necessarily in one of the two previous cases (leaf or one-child). Hence, we spend an extra $O\left(h\right)$ steps to reach the predecessor/successor node, and then a constant number of steps to swap the data and remove. Hence, the number of steps for removal is $O\left(h\right)$.

**QED**

### Complexities of BST Operations

Finally, we look at both the worst case and average case.

#### Worst-Case Runtime

**Theorem.** The worst-case complexities of these BST operations is $O\left(n\right)$.

**Proof.**

A BST with $n$ nodes may have height $n$, in the degenerate case. Hence, the BST operations that would require searching to the end would, indeed, take $O\left(n\right)$ steps.

**QED**

#### Average-Case Runtime

Now, suppose we want to figure out how many steps the average BST operation would take on a tree with $n$ elements. As previous analyses showed, this depends heavily on the shape of the tree (degenerate vs non-degenerate). The following theorem essentially states that BSTs are, on average, non-degenerate to enough of a degree for substantial savings in running time.

We will be considering a uniform distribution on the nodes being inserted into an empty BST, which induces a distribution on the resulting BST. This distribution should feel very natural, since the order that elements are inserted in is precisely what gives the shape of the BST.

**Theorem.** The average-case complexities of these BST operations is $O\left(\lg n\right)$.

*Note: The proof will be a bit more involved than usual. In fact, we need to prove a combinatorial lemma, first.*

**Lemma.** $$\binom{n+3}{4} = \sum\_{0\leq i < n} \binom{i+3}{3}.$$

**Proof.**

We proceed by induction.

Base case ($n = 2$): $$\sum\_{0\leq i < 2} \binom{i + 3}{3} = \binom{3}{3} + \binom{4}{3} = 1 + 4 = 5 = \frac{5!}{4!\cdot 1!} = \binom{5}{4} = \binom{n + 3}{4}.$$

Inductive case: Suppose it holds for $n$. Then, $$\sum\_{0\leq i < n+1} \binom{i + 3}{3} = \sum\_{0\leq i < n} \binom{i + 3}{3} + \binom{n+3}{3} = \binom{n+3}{4} + \binom{n+3}{3} = \frac{\left(n+3\right)!}{\left(n-1\right)! 4!} + \frac{\left(n+3\right)!}{n! 3!}$$

$$= \frac{n\left(n+3\right)!}{n! 4!} + \frac{4\left(n+3\right)!}{n! 4!} = \frac{\left(n+4\right)!}{n! 4!} = \binom{n + 4}{4},$$

as required.

**QED**

*We will also need the following, the proof of which is beyond the scope of this course.*

**Jensen's Inequality.** Let $\varphi$ be a convex function and $X$ a random variable. Then, $\varphi\left(\mathbb{E}\left[X\right]\right)\leq \mathbb{E}\left[\varphi\left(X\right)\right]$.

**Proof of Theorem.** [See: CLRS 3rd edition, Chapter 12, Section 4]

Let $H\_{n}$ be a random variable denoting the height of a BST with $n$ nodes.

Choose the $i\rm{th}$ node (in terms of their order) uniformly at random to be the `root`. Then, the left subtree has $i-1$ elements, and the right subtree has $n-i$ elements. Since BSTs are recursively defined, we have the following relation:

$$H\_{n} = 1 + \max\left\lbrace H\_{i}, H\_{n-i}\right\rbrace,$$

where the $1$ added is to account for the extra step from the `root` to whichever subtree has more elements.

For reasons that will make more sense later, we define an analogous random variable, called the *exponential height*, $\widetilde{H}\_{n} = 2^{H\_{n}},$ which turns the above relation into $\widetilde{H}\_{n} = 2 \max\left\lbrace \widetilde{H}\_{i}, \widetilde{H}\_{n-i}\right\rbrace$.

Since we're picking elements uniformly, $\mathbb{P}\left[i\right] = \frac{1}{n}$ for each $i$. Hence,

$$\mathbb{E}\left[ \widetilde{H}\_{n}\right] = \sum\_{0\leq i < n}\mathbb{P}\left[i\right] \mathbb{E}\left[2 \max\left\lbrace \widetilde{H}\_{i}, \widetilde{H}\_{n-i} \right\rbrace\right] = \frac{2}{n} \sum\_{0\leq i < n} \mathbb{E}\left[\max\left\lbrace \widetilde{H}\_{i}, \widetilde{H}\_{n-i} \right\rbrace\right]$$

$$\leq \frac{2}{n} \sum\_{0\leq i < n} \mathbb{E}\left[\widetilde{H}\_{i}\right] + \frac{2}{n}\sum\_{0\leq i < n} \mathbb{E}\left[\widetilde{H}\_{n-i}\right] = \frac{4}{n} \sum\_{0\leq i < n} \mathbb{E}\left[\widetilde{H}\_{i}\right].$$

*Claim.* $\mathbb{E}\left[ \widetilde{H}\_{n}\right]\leq \frac{1}{4}\binom{n+3}{3}$.

*Proof of Claim.* We proceed by induction.

Base case ($n = 1$): When there is 1 node in the tree, there are 0 steps in any path from the `root` to a leaf (because the `root` is a leaf). Hence, $\mathbb{E}\left[\widetilde{H}\_{1}\right] = 2^{0} = 1 \leq 1 = \frac{1}{4}\binom{4}{3}$.

Inductive case: Suppose this is true for $n$. Then, $$\mathbb{E}\left[\widetilde{H}\_{n+1}\right] \leq \frac{4}{n}\sum\_{i\leq 0\leq n} \mathbb{E}\left[\widetilde{H}\_{i}\right] \leq \frac{4}{n}\sum\_{0\leq i\leq n} \frac{1}{4} \binom{i+3}{3} = \frac{1}{n}\sum\_{0\leq i\leq n} \binom{i+3}{3} = \frac{1}{n} \binom{n + 3}{4} = \frac{4}{n} \binom{n+3}{3},$$ as required. $\blacksquare$

Now that we've bounded $\mathbb{E}\left[\widetilde{H}\_{n}\right]$, we'll use Jensen's inequality to get a bound on $\mathbb{E}\left[H\_{n}\right]$ (since $f\left(x\right) = 2^{x}$ is a convex function).

$$2^{\mathbb{E}\left[H\_{n}\right]}\leq \mathbb{E}\left[2^{H\_{n}}\right] = \mathbb{E}\left[\widetilde{H}\_{n}\right]\leq \frac{4}{n}\binom{n+3}{3} = O\left(n^{3}\right).$$

Hence, $$\mathbb{E}\left[H\_{n}\right]\leq O\left(\lg\left(n^{3}\right)\right) = O\left(\lg n\right),$$ as required.

Since the average height of a BST with $n$ nodes is $O\left(\lg n\right)$, this means that the average-case complexities of the three BST operations we're analyzing are also $O\left(\lg n\right)$.

**QED**

It's understandable if this final theorem isn't as satisfying as one might like. We shouldn't have to roll dice and hope to get a good tree to work with, and who knows if this logarithmic height will always be the case as we insert and remove elements?

We will see a nice way to *augment* our BST in the future to help maintain this logarithmic height without adversely affecting performance by enough to change the asymptotic runtime. However, that isn't what we'll look at next.

**Next: [Skip Lists & Randomization in Computing](./10.SkipLists.md)**