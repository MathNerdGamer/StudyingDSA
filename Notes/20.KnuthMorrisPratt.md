# Pattern Matching Algorithms II: Knuth-Morris-Pratt

* Like with Boyer-Moore, the Knuth-Morris-Pratt (KMP) algorithm begins with some preprocessing.

## Preprocessing: Failure Table

* The KMP algorithm preprocesses the pattern into what's called the *failure table*.

* The failure table is an array of $m$ integers which is used to determine the pattern shift on a mismatch.
    * It focuses on prefixes of the pattern.
    * At each index of the array, `fail[i]` represents the length of the longest prefix that is also a *proper* suffix (meaning it's not the whole string) of the subarray `pattern[0:i]`.

* Here's source code for building the failure table:
    ```java
    public static int[] failureTable(String pattern) {
        int m = pattern.length();
        int[] fail = new int[m];

        for (int prefixIndex = 0, queryIndex = 1; queryIndex < m; /* blank */) {
            if (pattern[prefixIndex] == pattern[queryIndex]) {
                fail[queryIndex] = prefixIndex + 1;
                prefixIndex++;
                queryIndex++;
            } else if (prefixIndex == 0) {
                fail[queryIndex] = 0;
                queryIndex++;
            } else {
                prefixIndex = fail[prefixIndex - 1];
            }
        }

        return fail;
    }
    ```

**Proposition.** Building the failure table takes $O\left(m\right)$ time.

**Proof.**

Note that the query index can only move forward or stay put. If it moved forward every step, the algorithm would immediately be $O\left(m\right)$, so now we must analyze what happens when the query index doesn't increment.

Note that this happens if and only if the prefix index moves backwards. However, the prefix index can only move backwards until it reaches 0, so it must eventually stop (and, hence, the query index must eventually move forward). Also, the prefix index only moves forward by at most 1 each step.

Therefore, the prefix index can only move backwards a total of $m$ times, which means the query index stays put at most $m$ times, and so we only get another additive $O\left(m\right)$ term to our runtime compared to if the query index always moved forward, which means that our total runtime is $O\left(m\right)$.

**QED**

## The Algorithm

* Before looking at the specifics of the KMP algorithm, let's start with a comparison with Boyer-Moore.
    * When a mismatch occurs, both algorithms use a table to determine how to realign the pattern with the text.
        * In Boyer-Moore, this is the last occurrence table, which queries using the mismatched text character; in this case, realigning causes the mismatched character to now match.
        * In KMP, this is the failure table, which queries using the mismatched pattern index (in particular, at index `pIdx - 1`); in this case, *all* characters before the mismatch will match.
    * Both algorithms compare text-to-pattern linearly.
        * In Boyer-Moore, the comparison is from the end of the pattern to the beginning.
        * In KMP, the comparison is from the beginning of the pattern to the end.

* Here's source code for the algorithm:
    ```java
    public static int KnuthMorrisPrattSingle(String text, String pattern) {
        int n = text.length();
        int m = pattern.length();
        int[] fail = failureTable(pattern);

        for (int tIdx = 0, pIdx = 0; tIdx < n; /* blank */) {
            if (pattern[pIdx] == text[tIdx]) {
                if (pIdx == m - 1) {
                    return tIdx - pIdx;
                } else {
                    pIdx++;
                    tIdx++;
                }
            } else if (pidx == 0) {
                tIdx++;
            } else {
                pIdx = fail[pIdx - 1];
            }
        }
    }
    ```

* The above only works for a single occurrence.
    * To modify for all occurrences, instead of `return tIdx`, we add `tIdx` to a list and set `pIdx = fail[m - 1]`.

**Theorem.** The KMP Algorithm has the following complexities:

1. If there are no occurrences of the pattern in the text:
    * Best-case: $O\left(m + n\right)$
    * Worst-case: $O\left(m + n\right)$
2. If we're looking only for a single occurrence:
    * Best-case: $O\left(m\right)$
    * Worst-case: $O\left(m + n\right)$
3. If we're looking for all occurrences:
    * Best-case: $O\left(m + n\right)$
    * Worst-case: $O\left(m + n\right)$

**Proof.**

The $O\left(m\right)$ term comes from building the failure table.

In all three cases, for the worst case, note that the loop is similar as that of the failure table building algorithm. In fact, a similar argument can be made that we can only iterate $O\left(n\right)$ times in the loop, and so there's the $O\left(n\right)$ term for all three worst cases.

For the best-case runtimes, note that in cases 1 and 3, we have to iterate through the entire text before we can either rule out everything or find all occurrences in the best case, so we still get that $O\left(n\right)$ term. In case 2, an occurrence could show up immediately, and so we only loop through a total of $m$ characters, giving the $O\left(m\right)$ best case.

**QED**

**Next: [Pattern Matching Algorithms III: Rabin-Karp](./21.RabinKarp.md)**