### Recursion
* A *recursive* method has the three following properties:
    * The method must call itself.
    * It must have at least one base case so that the recursion eventually stops.
    * The method must make progress towards a base case.

* A typical recursive method looks something like this:
    ```java
    public returnType recursiveMethod(paramType param1, ..., paramType paramN) {
        if (baseCase1) {
            // termination for base case 1
        } else if (baseCase2) {
            // termination for base case 2
        } /* . . . other base cases . . . */ else {
            // new parameters to recurse on to make progress towards base cases
            return f(recursiveMethod(newParam11, ..., newParamN1), ..., recursiveMethod(newParam1M, ..., newParamNM));
        }
    }
    ```
    * In the above pseudocode, we use a function `f` to denote some operation that may require multiple recursive branches.

* Here are some examples of recursive methods:
    * `Factorial`
    ```java
    public static int factorial(int n) {
        if (n <= 1) {
            return 1;
        }

        return n * factorial(n - 1);
    }
    ```

    * `Fibonacci sequence` (handles negative integers).
    ```java
    public static int fibonacci(int n) {
        if (n == 0 || n == 1) {
            return n;
        }

        int m = n;
        int factor = 1;

        if (n < 0) {
            m = -n;

            if (n % 2 == 0) {
                factor = -1;
            }
        }

        return factor * (fibonacci(m - 1) + fibonacci(m - 2));
    }
    ```

    * `Exponentiation by Repeated Squaring`
    ```java
    public static int ipower(int b, int x) {
        if (x == 0) {
            return 1;
        } else if (x == 1) {
            return b;
        }

        int halfPower = ipower(b * b, x / 2);

        if (x % 2 == 0) {
            return halfPower;
        } else {
            return b * halfPower;
        }
    }
    ```

    * `Euclidean Algorithm` (to find Greatest Common Divisor)
    ```java
    public static int gcd(int a, int b) {
        if (a < b) {
            return gcd(b, a);
        }

        if (b == 0) {
            return a;
        }

        int r = a % b;

        if (r == 0) {
            return b;
        }

        return gcd(b, r);
    }
    ```

* Here, we will analyze the `Exponentiation by Repeated Squaring` algorithm presented above.

**Theorem.** The `Exponentiation by Repeated Squaring` is correct and takes $O\left(\lg{x}\right)$ multiplications.

**Proof.** [Correctness] We proceed by induction on $x$.

Base Case [x = 0, 1]: In the base cases, $b^{0} = 1$ and $b^{1} = b$ are correctly computed.

Inductive Case: Suppose that the algorithm is correct for each integer less than $x$. Then, there are two cases.

* Case 1 [$x$ is even]: When $x$ is even, `halfPower` is $\left(b^{2}\right)^{x/2} = b^{x}$, and so this branch is correct.

* Case 2 [$x$ is odd]: When $x$ is odd, since the division is *integer division*, we have that `halfPower` is actually $b^{2\cdot\lfloor x/2 \rfloor}$, and so multiplying it by $b$ gives $b\cdot b^{2\cdot\lfloor x/2 \rfloor} = b^{x}$. This is because $\lfloor x/2\rfloor = x/2 - 1/2$, and so we get $2\cdot\lfloor x / 2 \rfloor = x - 1$ in the exponent of $b$ for `halfPower`, and the final factor of $b$ corrects this discrepancy to give $b^{x}$. Therefore, this branch is also correct.

[Efficiency] Let $M\left(x\right)$ denote the number of multiplications by our method. Then, $M\left(x\right) = M\left(x/2\right) + O\left(1\right)$. This reduces to $M\left(x\right) = O\left(\lg{x}\right)$, as required.

**QED**

* A more detailed analysis shows that the number of multiplications is actually one less than the number of times $1$ appears in the binary expansion of $x$.

* The `Fibonacci sequence` algorithm above is correct, but is terribly inefficient. In fact, the number of steps taken is precisely $\Theta\left(F_{\left|n\right|}\right)$, where $F_{n}$ is the $n\text{th}$ Fibonacci number. Those who know a little number theory should recognize, then, that this means the algorithm is $\Theta\left(\varphi^{\left|n\right|}\right)$, where $\varphi = \frac{1+\sqrt{5}}{2}$ is the so-called *golden ratio*. In particular, this means that the algorithm has exponential complexity.
    * The reason for this is due to our recursive calls doing the same work twice. When we call `fibonacci(n - 1)`, we do the work of `fibonacci(n - 2)` before finally returning to the top of the `fibonacci` call stack, but then we immediately recurse back into `fibonacci(n - 2)`.

* Given the recursive form of a method, we may turn it into an iterative algorithm by simulating the call stack with an array. However, in some cases, we can even remove the stack altogether by reusing space while also making it more efficient. For example, consider the following iterative form of the `Fibonacci sequence` method:
    ```java
    public int fibonacci(int n) {
        if (n == 0 || n == 1) {
            return n;
        }

        int m = n;
        int factor = 1;

        if (n < 0) {
            m = -n;

            if (n % 2 == 0) {
                factor = -1;
            }
        }

        int f0 = 0;
        int f1 = 1;
        int f2 = 1;

        for (int i = 2; i <= m; i++) {
            f2 = f0 + f1;
            f0 = f1;
            f1 = f2;
        }

        return factor * f2;
    }
    ```
    * This iterative form actually only takes $\Theta\left(n\right)$ operations, because we don't do work that's already been done.

* Consider the following problem:

#### Increasing Subsequence Problem
Let $A$ be an array of $n$ distinct integers. A *subsequence* of $A$ is a sequence made up of elements of $A$ in the same relative order as they appear in $A$. For example, some subsequences of the array $A = \left[1, 7, 2, 0, 11, 12\right]$ are $\left[1, 11\right]$, $\left[7, 2, 0, 12\right]$, and $A$, itself. However, $\left[7, 1, 12\right]$ is not a subsequence of $A$, because $1$ does not come after $7$ in $A$.

An *increasing subsequence* is a subsequence which, when considered as an array on its own, is sorted in increasing order. For example, $\left[1, 11\right]$ is an increasing subsequence, but $\left[7, 2, 0, 12\right]$ is not.

We want to count the number of increasing subsequences in $A$. Where we can use recursion is by considering subproblems of our main problem. For notational simplicity, we will be indexing starting at $1$.

For each $0\leq i\leq n$, let $a_{i}$ denote the number of increasing subsequences that end with the element at index $i$, where we treat the index $0$ as corresponding to the empty subsequence (which we will take to be increasing). Then, the answer to our problem is
$$\sum_{0\leq i\leq n} a_{i}.$$

Since we're considering the empty subsequence to be increasing, we have $a_{0} = 1$ as our base case. For each other $a_{i}$, we have the following relationship:
$$a_{i} = \sum_{\substack{0\leq j < i\\ A[j] < A[i]}} a_{j}.$$

*Why?* For each $0\leq j < i$ such that $A[j] < A[i]$, an increasing subsequence of $A$ ending at index $j$ can be turned into an increasing subsequence ending at index $i$ by simply appending $A[i]$ to the end.

From this, we can convert this into the following iterative algorithm:

```java
public static int increasingSubsequence(int[] A) {
    int[] a = new int[A.length]; // Default assigns all to 0.

    for (int i = 0; i < A.length; i++) {
        a[i] = 1; // Base case added in by default.
        for (int j = 0; j < i; j++) {
            if (A[j] < A[i]) {
                a[i] += a[j];
            }
        }
    }

    int sum = 1; // Base case added in by default.
    for (int i = 0; i < A.length; i++) {
        sum += a[i];
    }

    return sum;
}
```
Note that we actually stuck to indexing from $0$ because it's more convenient programmatically. Instead of explicitly storing the base case, we simply set `a[i]` to `1` before the inner loop to count the base case. When it came time to get the final sum, we started our sum at $1$ to account for the base case.

The time complexity of this algorithm is $\Theta\left(n^{2}\right)$ with a space complexity of $\Theta\left(n\right)$ due to having to allocate a separate array for subproblems.

**Next: [Linked Lists](./5.LinkedLists.md)**