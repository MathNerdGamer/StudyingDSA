# Analysis of Iterative Sorting Algorithms

## Correctness

* There will be a lot of induction here.

* Also, note that these proofs are almost trivial because the algorithms, themselves, are.

**Theorem.** Bubble Sort is correct.

**Proof.**

We proceed by induction.

Base Case ($n = 1$): An array of length 1 is, by definition, sorted.

Inductive Case: Suppose that bubble sort correctly sorts any array of size $\leq n$. Consider an array $A$ of size $n + 1$.

In the first iteration of the outer loop, the largest element will be in the final position, leaving a subarray of size $n$ to be sorted. Because of the way bubble sort works, this is equivalent to sorting an array of size $n$, which bubble sort does correctly, by assumption. Since the left $n$ elements must necessarily be less than the final element, we have that the end result is a sorted array, as required.

**QED**

**Theorem.** Insertion Sort is correct.

**Proof.**

We proceed by induction.

Base Case ($n = 1$): An array of length 1 is, by definition, sorted.

Inductive Case: Suppose that insertion sort correctly sorts any array of size $\leq n$. Consider an array $A$ of size $n + 1$.

In the first iteration of the outer loop, the smallest element will be in the first position, leaving a subarray of size $n$ to be sorted. Because of the way insertion sort works, this is equivalent to sorting an array of size $n$, which insertion sort does correctly, by assumption. Since the right $n$ elements must necessarily be greater than the first element, we have that the end result is a sorted array, as required.

**QED**

**Theorem.** Selection Sort is correct.

**Proof.**

We proceed by induction.

Base Case ($n = 1$): An array of length 1 is, by definition, sorted.

Inductive Case: Suppose that selection sort correctly sorts any array of size $\leq n$. Consider an array $A$ of size $n + 1$.

In the first iteration of the outer loop, the smallest element will be in the first position, leaving a subarray of size $n$ to be sorted. Because of the way selection sort works, this is equivalent to sorting an array of size $n$, which selection sort does correctly, by assumption. Since the right $n$ elements must necessarily be greater than the first element, we have that the end result is a sorted array, as required.

**QED**

## Best-Case Analyses

* We will prove the result for bubble sort and insertion sort together.

**Theorem.** The best-case numbers of comparisons for bubble sort and insertion sort are $\Theta\left(n\right)$.

**Proof.**

Since both algorithms must iterate through the array at least once in their first outer loop iteration, they both make $\Omega\left(n\right)$ comparisons.

The best case array for both is an already-sorted array. In this case, bubble sort finishes after the first outer loop iteration, while insertion sort's inner loop is never entered.

During the first iteration of the outer loop for bubble sort, the inner loop runs for its $O\left(n\right)$ iterations, with $O\left(n\right)$ comparisons, but since no elements are swapped, bubble sort terminates right after. This gives $O\left(n\right)$ best-case number of comparisons.

During the first iteration of the outer loop for insertion sort, any time we come to the inner loop, the `array[i] > nextInsert` condition always fails, and so we skip it, which means we leave the current element in the same spot we found it. Hence, the inner portion makes $O\left(1\right)$ comparisons for a total of $O\left(n\right)$ iterations, giving $O\left(n\right)$ best-case number of comparisons.

**QED**

* The following theorem for selection sort will make all of the performance analyses trivial.

**Theorem.** Selection sort makes exactly $\frac{n\left(n-1\right)}{2}$ comparisons on *any* input of size $n$.

**Proof.**

On the first iteration of selection sort, it makes $n-1$ comparisons since it always moves forward, starts comparing from the first element, and it compares at every step.

On each subsequent iteration, it makes one fewer comparisons compared to the previous iteration. Since it makes a total of $n-2$ iterations, the total number of comparisons is

$$\sum_{1\leq k\leq n-1} k = \frac{n\left(n-1\right)}{2},$$

as required.

**QED**

**Corollary.** The best-, worst-, and average-case number of comparisons for selection sort are all $\Theta\left(n^{2}\right)$.

**Proof.**

Every case is the worst case, hence also the best case, and taking the average over a bunch of numbers that are the same gives you that same number.

**QED**

## Worst-Case Analyses

**Theorem.** The worst-case number of comparisons for bubble sort is $O\left(n^{2}\right)$.

**Proof.**

The worst case input is an array of distinct elements in reverse order, as `lastSwap` will always be set to `endIndex - 1` at each iteration (making it no better than the unoptimized form).

Because of this, the $k\rm{th}$ iteration of the outer loop must compare $n-k$ elements. Hence, the total number of comparisons is

$$\sum_{0\leq k\leq n-1} \left(n - k\right) = \sum_{0\leq k\leq n-1} k = \frac{n\left(n-1\right)}{2} = O\left(n^{2}\right).$$

**QED**

**Theorem.** The worst-case number of comparisons for insertion sort is $O\left(n^{2}\right)$.

**Proof.**

Again, the worst case input is an array of distinct elements in reverse order, since the `array[i] > nextInsert` condition for the inner loop will always be satisfied. Therefore, on the $k\rm{th}$ iteration of the outer loop, there will be $k$ comparisons, and so the total number of comparisons is

$$\sum_{0\leq k\leq n-1} k = \frac{n\left(n-1\right)}{2} = O\left(n^{2}\right),$$

as required.

**QED**

## Average-Case

For the average-case result, we will need the notion of *inversions*.

**Definition.** Given an array $A$ of $n$ elements from the set $\left\lbrace 1,\ldots, n \right\rbrace$, an *inversion* is a pair of indices $i < j$ such that $A\left[i\right] > A\left[j\right]$.

**Lemma.** The number of inversions is equal to the number of swaps made by bubble sort.

**Proof.**

Since the only way for bubble sort to change the relative order of elements in an array is by swapping, we have that the number of swaps is at least equal to the number of inversions.

Since bubble sort only swap in cases that lower the number of inversions, this gives us that the number of inversions is at least the number of swaps made.

Therefore, they are equal.

**QED**

**Theorem.** Consider a uniform distribution over all possible arrays of length $n$ from $\left\lbrace 1,\ldots, n \right\rbrace$. The average-case numbers of comparisons for bubble sort is $\Theta\left(n^{2}\right)$.

**Proof.**

Since the worst case is $O\left(n^{2}\right)$, the function modeling the average case must also be $O\left(n^{2}\right)$. Therefore, we need only prove that the average case is $\Omega\left(n^{2}\right)$.

To that end, note that the number of comparisons will always at least the number of swaps made. Therefore, if we can prove that the expected number of swaps is $\Omega\left(n^{2}\right)$, we'll be done. Since the number of swaps made is precisely the number of inversions in our array, we can instead analyze this.

Let $R\left(A\right)$ denote the reverse array of an array $A$. Then, either $i < j$ is an inversion in $A$, or it is an inversion in $R\left(A\right)$. Since we're considering a uniform distribution, either case has an equal probability. Since there are $\frac{n\left(n-1\right)}{2}$ pairs of indices $i < j$, there is an expected $\frac{n\left(n-1\right)}{4}$ inversions in our array.

Since the number of inversions is equal to the number of swaps, which is no greater than the number of comparisons, bubble sort will make $\Omega\left(n^{2}\right)$ comparisons on average, and so we are done.

**QED**

**Theorem.** Consider a uniform distribution over all possible arrays of length $n$ from $\left\lbrace 1,\ldots, n \right\rbrace$. The average-case numbers of comparisons for insertion sort is $\Theta\left(n^{2}\right)$.

**Proof.**

Again, since the worst case is $O\left(n^{2}\right)$, the function modeling the average case must also be $O\left(n^{2}\right)$. Therefore, we need only prove that the average case is $\Omega\left(n^{2}\right)$.

Since our implementation of insertion sort doesn't use explicit swaps, we have to change our analysis slightly.

On iteration $j\in\left\lbrace 1,\ldots, n-1\right\rbrace$, we do at most $j + 2$ array assignments after $j + 1$ comparisons. Hence, we have at most 1 fewer comparisons compared to array assignments per iteration.

Since the only way for the number of inversions to decrease is via these array assignments, we need $\Omega\left(n^{2}\right)$ assignments on average. The total number of comparisons is only $O\left(n\right)$ fewer, which means we need $\Omega\left(n^{2}\right)$ comparisons, as required.

**QED**

**Next: [Divide & Conquer Sorting Algorithms](./17.DivideAndConquerSorts-I.md)**

**Alternative: [Array Accesses of Iterative Sorting Algorithms](./16a.ArrayAccesses.md)**