# Binary Heaps

## Binary Heap Structure

* A (*binary*) *heap* is a type of binary tree that *must* be complete, which helps with storing in their contents arrays.
    * This is because we can store elements in the order they're accessed when doing a levelorder traversal.

* The most common forms of heaps are the *min heap* and *max heap*, which have the following order property (we state the min heap property here, the max heap property is analogous):
    * The data in child nodes are larger than the data in the parent.

* As a consequence of this property, the smallest element in the tree is the `root` node.

* To implement a binary heap as an array, as stated above, we use levelorder traversal. This can done more explicitly by using an array from the beginning (rather than implementing with nodes and pointers) and using the following formulas:
    * Index $0$ is the `root` node.
    * To move from the $i\rm{th}$ "node" to the `left` child, simply move to index $2i+1$.
    * To move from the $i\rm{th}$ "node" to the `right` child, simply move to index $2i+2$.
    * Before doing this move, make sure that the index being moved to is less than the size of the array, or else we would be moving to "`null` nodes" in the (conceptual) binary tree.
    * To get from the $i\rm{th}$ "node" to its `parent`, we have three cases:
        * If $i = 0$, then we either don't move or return some value that can be used as a sentinel, like $-1$.
        * If $i$ is even, move to $\left\lfloor\frac{i - 1}{2}\right\rfloor$. This works because we get to an even (non-zero) index whenever we went down a `right` edge from the parent, which means $i = 2j + 2$ for some $j$, and so $\left\lfloor\frac{i - 1}{2}\right\rfloor = \left\lfloor\frac{2j + 1}{2}\right\rfloor = j$.
        * If $i$ is odd, move to $\left\lfloor\frac{i}{2}\right\rfloor$. This works because we get to an odd index whenever we went down a `left` edge from the parent, which means $i = 2j + 1$ for some $j$, and so $\left\lfloor\frac{i}{2}\right\rfloor = \left\lfloor\frac{2j + 1}{2}\right\rfloor = j$.
        * Note that we implicitly do a $\lfloor\cdot\rfloor$ operation whenever we divide integers in many programming language (such as Java and C, which is what we'll be using to implement this).

* We can implement helper functions for the `left`, `right`, and `parent` entries:

```java
private int leftChild(int index) {
    return 2 * index + 1;
}

private int rightChild(int index) {
    return 2 * index + 2;
}

private int parent(int index) {
    if (index == 0) { // root
            return -1; // Use -1 as a sentinel when walking up a heap.
    } else if (index % 2 == 0) { // Right child
        return (index - 1) / 2;
    } else { // Left child
        return index / 2;
    }
}
```

* The reason why this array works is because the "tree" (conceptually) backing a binary heap is complete, and so the only time the formulas don't work is if we've reached one of the ends of the array and would be going out of bounds.

## Binary Heap `add`/`remove` Operations

* Heap operations are not designed to deal with arbitrary data, and so all that will be needed are methods for `add(T)` and `remove()`.

* When performing these operations, we have to make sure that the resulting tree ends up still being complete and still maintains the order property.

* To implement `add(T)`, we put the data at the end of the heap (in our case, this means at the end of our array), which can't break the completeness of the tree. Then, we perform some shape-preserving shuffling to make sure the order property is preserved at the end.
    * This shuffling procedure is referred to as `heapify`, with this specifically being called `upHeap()`, `bubbleUp()`, or various other names. We will stick with the name `upHeap()` for the method. The analogous names are used for `remove()` later.
    * First, compare the new data with its parent.
    * If the new data and parent's data don't satisfy the appropriate order relationship, swap.
    * Repeat until either the new data is the `root` node or until the order property is satisfied between the node and its parent. This is enough to ensure that the order property holds for the entire heap, because we only disrupted the order property along the line that our new node was on.

* When implementing these operations, we will use an `ArrayList<T>` as the backing (dynamic) array.

* Here is an implementation of `add(T)`, with a helper function, `greaterThan()`, to improve readability somewhat:

```java
public void add(T data) {
    array.add(data);

    upHeap(array.size() - 1);
}

private void upHeap(int index) {
    for (int i = index; i > 0; i = parent(i)) {
        if (lessThan(i, parent(i))) { // Need to fix order.
            T temp = array.get(i);    // Swap values as necessary.
            array.set(i, array.get(parent(i)));
            array.set(parent(i), temp);
        } else { // If order is fine here, then we can stop.
            break;
        }
    }
}

private boolean lessThan(int index, int child) {
    if (child > array.size()) {
        return false;
    }
    return array.get(index).compareTo(array.get(child)) < 0;
}
```

* While appending elements to the end of the array is an $O\left(1\right)$ (amortized) operation (since this is just a dynamic array), the `heapify` part is $O\left(\lg n\right)$, giving a total $O\left(\lg n\right)$ (amortized) runtime.

* To implement `remove()`, swap the `root` with the last node in the heap and then remove the old `root`. Then, as before, we perform some shape-preserving shuffling to rectify the messed up order.
    * This shuffling procedure is also referred to as `heapify`, though we'll call the method `downHeap()`.
    * We first compare our node with its child (if any).
       * If there are no children (our node is a leaf), or if the children are below our node with respect to our heap's order property, then no swap is required and we terminate.
       * If the order property is violated between the node and its child, we'll need to swap.
           * If there were two children, swap with the child who comes above the other child with respect to the order property.
           * If there was only one child, then we swap with it.
       * Repeat at our node's new position until we terminate. Terminating is enough to ensure that the order property holds for the entire heap, because we only really disrupted the order property along the line that our node traveled from the `root`.

* Here is an implementation of `remove()`, with a helper function, `greaterThan()`, to improve readability somewhat:

```java
public T remove() {
    if (array.isEmpty()) {
        return null;
    }

    T data = array.get(0);
    array.set(0, array.remove(array.size() - 1));

    downHeap(0);

    return data;
}

private void downHeap(int index) {
    while (index < array.size()) { // We walk down the heap.
        int leftIndex = leftChild(index);
        int rightIndex = rightChild(index);
        boolean leftChildSwap = leftIndex < array.size() && greaterThan(index, leftIndex);
        // leftChildSwap = true if the left child is a viable candidate for swapping.
        boolean rightChildSwap = rightIndex < array.size() && greaterThan(index, rightIndex);
        // rightChildSwap = true if the right child is a viable candidate for swapping.
        int newIndex = 0;

        if (leftChildSwap && rightChildSwap) { // If both viable, find the optimal child to swap.
            if (greaterThan(rightIndex, leftIndex)) {
                rightChildSwap = false;
            } else {
                leftChildSwap = false;
            }
        }

        if (leftChildSwap) {
            newIndex = leftIndex;
        } else if (rightChildSwap) {
            newIndex = rightIndex;
        } else { // If neither are viable, order is restored.
            break;
        }

        T temp = array.get(index); // Swap values.
        array.set(index, array.get(newIndex));
        array.set(newIndex, temp);
        index = newIndex;
    }
}

private boolean greaterThan(int index, int child) {
    if (child > array.size()) {
        return false;
    }
    return array.get(index).compareTo(array.get(child)) > 0;
}
```

* While swapping the `root` and last element is an $O\left(1\right)$ operation, it is again the `heapify` operation that contributes the $O\left(\lg n\right)$ steps that becomes the final runtime.

## The Build Heap Algorithm

Suppose we have a bunch of unsorted, unordered data that we want to build a heap out of. Building the heap na√Øvely would incur a runtime of $O\left(n \lg n\right)$. Can we do better?

* Recall that removing an item involves using the `downHeap()` method to restore the order relation. However, the order property was still preserved for the two subtrees below the `root` when viewed as two separate subheaps.

* We will make use of this when implemeting the `buildHeap()` method.
    * First, place the data in order as presented into the array.
    * We then `downHeap()` starting from the last element that has a child and continuing in reverse levelorder to the `root` to produce valid subheaps.
    * As a result, whenever we reach an index of the array while moving up, the children will already be valid subheaps.
    * Therefore, when we finish using `downHeap()` at the `root` node, we'll have finished building our heap.

* Here is an implementation of the Build Heap algorithm as a constructor with variadic arguments:

```java
MinHeap(T... A) {
    array = new ArrayList<>();

    for (T x : A) { // Add everything in order.
        array.add(x);
    }

    for (int index = parent(array.size()); index > -1; index--) {
        // Down heap up the heap from the last element with a child.
        downHeap(index);
    }
}
```

**Theorem.** When given $n$ items to build a heap from, the build heap algorithm takes $O\left(n\right)$ steps.

**Proof.**

Recall that a binary heap is a complete binary tree. We will make use of the following two facts for complete binary trees, which will be proved after this theorem:
1. There are exactly $\displaystyle{\left\lfloor \lg\left(n\right)\right\rfloor} + 1$ levels in the tree.
2. There are $\displaystyle{\leq \left\lceil \frac{n}{2^{h+1}} \right\rceil}$ nodes at any given height $h$.

In general, the time complexity to heapify a single node at height $h$ is $O\left(h\right)$, and so the total number of steps at any given height $h$ is $\displaystyle{\leq \left\lceil \frac{n}{2^{h+1}} \right\rceil \cdot O\left(h\right)}$. Hence, the total time for all heights, from $0$ to $\left\lfloor \lg\left(n\right)\right\rfloor + 1$, is

$$\leq \sum_{0\leq h\leq \left\lfloor \lg\left(n\right)\right\rfloor + 1} \left\lceil \frac{n}{2^{h+1}} \right\rceil \cdot O\left(h\right) = $$

$$O\left(n \sum_{h\geq 0} \frac{h}{2^{h}} \right) = O\left(n\right),$$

where the final equality comes from the fact that the infinite sum converges.

**QED**

We prove the two facts given above:

**Lemma.**
1. There are exactly $\displaystyle{\left\lfloor \lg\left(n\right)\right\rfloor} + 1$ levels in a complete binary tree with $n$ nodes.
2. There are $\displaystyle{\leq \left\lceil \frac{n}{2^{h+1}} \right\rceil}$ nodes at any given height $h$ in a complete binary tree with $n$ nodes.

**Proof.**

We prove the first statement by induction on the number of items.

Base case ($n = 0$): In an empty binary tree, there are $0$ levels.

Inductive case: Suppose that there are $\ell = \left\lfloor \lg\left(n\right)\right\rfloor + 1$ levels in any complete binary tree with $n$ nodes. There are two cases when adding a new item.

Case 1 (no new level): If a new node doesn't increase the number of levels, then $n < 2^{\ell} - 1$, and so $\left\lfloor\lg\left(n+1\right)\right\rfloor = \left\lfloor\lg\left(n\right)\right\rfloor$. Therefore, after adding a node, there will be $\ell = \left\lfloor \lg\left(n\right)\right\rfloor + 1 = \left\lfloor \lg\left(n+1\right)\right\rfloor + 1$ levels.

Case 2 (new level): If a new node *does* increase the number of levels, then $n = 2^{\ell} - 1$. Then, $\left\lfloor\lg\left(n+1\right)\right\rfloor = \left\lfloor\lg\left(n\right)\right\rfloor + 1$, and so there will be $\ell + 1 = \left\lfloor \lg\left(n\right)\right\rfloor + 2 = \left\lfloor \lg\left(n+1\right)\right\rfloor + 1$ levels in the tree.

Therefore, by induction, there are exactly $\displaystyle{\left\lfloor \lg\left(n\right)\right\rfloor} + 1$ levels in a complete binary tree with $n$ nodes.

We also prove the second statement by induction, but this time on the height.

Base case ($h = 0$): In this case, the maximum is achieved if we have a perfect binary tree, and there are $\displaystyle{\left\lceil \frac{n}{2} \right\rceil}$ leaves.

Inductive case: Suppose that it's true that there are $\displaystyle{\leq \left\lceil \frac{n}{2^{h+1}} \right\rceil}$ nodes at height $h$. Now, consider the nodes at height $h+1$.

The maximum number of nodes are achieved precisely when we have a perfect binary tree down to the level where all nodes are at height $h+1$. Since we can have a maximum of $\displaystyle{\left\lceil \frac{n}{2^{h+1}} \right\rceil}$ nodes at height $h$, and this only happens if every node at height $h+1$ has two children, this means there must be half as many nodes at height $h+1$. Therefore, there are $\displaystyle{\leq \frac{1}{2}\left\lceil \frac{n}{2^{h+1}} \right\rceil \leq \left\lceil \frac{n}{2^{h+2}} \right\rceil}$ nodes at height $h+1$, as required.

**QED**

**Next: [Hash Maps](./12.HashMaps.md)**